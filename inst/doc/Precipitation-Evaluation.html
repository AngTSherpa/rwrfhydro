<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Background</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Background</h2>

<p>Forcing are stored in multiple files, either in input forcing files (such as LDASIN or PRECIP_FORCING files) or in output files (LDASOUT). LDASOUT files contains the variable ACCPRCP which stores the accumulated precipitation, and one can calculate the rainfall depth by subtracting two consecutive files. LDASIN and PRECIP_FORCING store rain rate in RAINRATE and precip_rate variables. MRMS is one of the precipitation product which can be used as supplementary forcing in WRF-Hydro and here we evaluate the MRMS at a few gauge locations and also in a grid format against stageIV data.</p>

<p>Load the rwrfhydro package. </p>

<pre><code class="r">devtools::install_github(&#39;arezoorn/rwrfhydro&#39;, ref=&#39;devBranch&#39;)
library(rwrfhydro)
</code></pre>

<h2>Import observed datasets</h2>

<h2>GHCN-daily</h2>

<p>Global Historical Climatology Network-Daily (GHCN-D) dataset contains daily data from around 80000 surface station in the world, which about two third of them are precipitation only (Menne et al. 2012). It is the most complete collection of U.S. daily data available (Menne et al. 2012). The dataset undergo an automated quality assurance which the details can be found in Durre et al. 2008; 2010. Data is available on <a href="http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/and">http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/and</a> is updated frequently. Data is available in two formats either categorized by gauge station or categorized by year. Accordingly, there are two function to pull GHCN-daily data from these two sources.</p>

<h3>Gauge selection</h3>

<p>First step is to select the gauges you want to use for verification based on some criteria. GHCN-daily contains the precipitation data from different sources such as COOP or CoCoRaHS. The selection criteria can be country code, states if country is US, type of rain gauge network (for example CoCoRaHS), or a rectangle domain. </p>

<pre><code class="r">countryCodeList=c(&quot;US&quot;)
networkCodeList=c(&quot;1&quot;,&quot;C&quot;)
sg &lt;- SelectGhcnGauges(countryCode=countryCodeList,
                                 networkCode=networkCodeList)
str(sg)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    48979 obs. of  12 variables:
##  $ country    : chr  &quot;US&quot; &quot;US&quot; &quot;US&quot; &quot;US&quot; ...
##  $ network    : chr  &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ...
##  $ stationID  : chr  &quot;0RMHS145&quot; &quot;0adam001&quot; &quot;0adam002&quot; &quot;0adam003&quot; ...
##  $ latitude   : num  40.5 40.6 40.5 40.5 40.5 ...
##  $ longitude  : num  -105.1 -98.5 -98.5 -98.7 -98.4 ...
##  $ elevation  : num  1569 598 601 615 570 ...
##  $ state      : chr  &quot;CO&quot; &quot;NE&quot; &quot;NE&quot; &quot;NE&quot; ...
##  $ name       : chr  &quot;RMHS 1.6 SSW                  &quot; &quot;JUNIATA 1.5 S                 &quot; &quot;JUNIATA 6.0 SSW               &quot; &quot;HOLSTEIN 0.1 NW               &quot; ...
##  $ GSNflag    : chr  &quot;   &quot; &quot;   &quot; &quot;   &quot; &quot;   &quot; ...
##  $ HCN/CRNflag: chr  &quot;   &quot; &quot;   &quot; &quot;   &quot; &quot;   &quot; ...
##  $ WMOID      : chr  &quot;    &quot; &quot;    &quot; &quot;    &quot; &quot;    &quot; ...
##  $ siteIds    : chr  &quot;US10RMHS145&quot; &quot;US10adam001&quot; &quot;US10adam002&quot; &quot;US10adam003&quot; ...
</code></pre>

<p>The sg dataframe has all the information provided by NCDC about each gauge. We only subset two gauges here. </p>

<pre><code class="r">sg &lt;- sg[seq(1,nrow(sg),100),]
</code></pre>

<h3>GetGhcn</h3>

<p>GetGhcn
GHCN-daily data are archived for each individual gauge in a text file in <a href="http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/all/">http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/all/</a>. Precipitating can be downloaded for a single site or multiple ones by setting element to &ldquo;PRCP&rdquo; and specifying the desired start and end date. </p>

<pre><code class="r">startDate=&quot;2015/06/01&quot;
endDate=&quot;2015/09/01&quot;
element=&quot;PRCP&quot;
obsPrcp&lt;-GetGhcn(sg$siteIds, element, startDate, endDate, parallel=FALSE)
</code></pre>

<h3>GetGhcn2</h3>

<p>NCDC also provides GHCN-daily categorized by year under <a href="http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/">http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/</a>. If the number of the gauges are high, GetGhcn2 is much faster in retrieving data. </p>

<pre><code class="r">startDate=&quot;2015/05/01&quot;
endDate=&quot;2015/10/01&quot;
element=&quot;PRCP&quot;
obsPrcp&lt;-GetGhcn2(sg$siteIds, element, startDate, endDate, parallel=FALSE)
head(obsPrcp)
</code></pre>

<pre><code>##       siteIds       date element value mFlag qFlag sFlag reportTime
## 1 USC00143527 2015-05-01    PRCP   0.0                 7       0800
## 2 USC00083470 2015-05-01    PRCP   0.0                 7       0800
## 3 USC00102942 2015-05-01    PRCP   0.0                 7       0700
## 4 US1NYMR0012 2015-05-01    PRCP   0.0                 N           
## 5 US1OHDR0018 2015-05-01    PRCP   0.3                 N           
## 6 US1FLHN0024 2015-05-01    PRCP   0.0                 N
</code></pre>

<h3>Import model datasets</h3>

<p>Here we verify the MRMS precipitation depth. Firs make a list of all files containing MRMS values.Sample data for MRMS is placed under &ldquo;/glade/scratch/arezoo/QPF_verification_rwrfhydro&rdquo;</p>

<pre><code class="r">dirPath&lt;-&quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/&quot;
pathMRMS &lt;- paste0(dirPath,&quot;mrms/&quot;)
files&lt;-list.files(path=pathMRMS,full.names = TRUE, pattern = &quot;PRECIP_FORCING&quot;)
</code></pre>

<p>Only lat/lon locations of rain gauges are available if you have retrieved your stations using SelectGhcnGauges function, it is required to find out the gauge location in the geogrid file (x,y) in order to pull the data from the netcdf files. Use GetGeogridIndex function in rwrfhydro and provide the address to the geogrid file.</p>

<pre><code class="r">geoGridAdd&lt;-&quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/geo_em.d01.nc.conus_3km_nlcd11&quot;
rainGgaugeInds &lt;- GetGeogridIndex(data.frame(lon=sg$longitude, lat=sg$latitude),
                                    geoGridAdd)
sg &lt;- cbind(sg,rainGgaugeInds)
head(sg)
</code></pre>

<pre><code>##       country network stationID latitude longitude elevation state
## 45643      US       1  0RMHS145  40.5268 -105.1113    1569.1    CO
## 45743      US       1  0buff013  40.6995  -99.4062     691.9    NE
## 45843      US       1  0chey004  41.1548 -103.1077    1324.1    NE
## 45943      US       1  0cust042  41.6273  -99.7410       0.0    NE
## 46043      US       1  0dund011  40.1548 -101.4734     929.0    NE
## 46143      US       1  0garf006  41.7862  -99.1309     651.1    NE
##                                 name GSNflag HCN/CRNflag WMOID     siteIds
## 45643 RMHS 1.6 SSW                                             US10RMHS145
## 45743 ELM CREEK 2.2 WSW                                        US10buff013
## 45843 SIDNEY 6.8 W                                             US10chey004
## 45943 ANSELMO 6.5 E                                            US10cust042
## 46043 MAX 4.6 WNW                                              US10dund011
## 46143 BURWELL 0.3 NNE                                          US10garf006
##        ew  sn
## 45643 547 671
## 45743 703 667
## 45843 604 688
## 45943 695 700
## 46043 646 649
## 46143 712 705
</code></pre>

<h3>Pull the data from netcdf file.</h3>

<p>One needs to prepare the file, var, and ind variables for GetMultiNcdf function as follows. You can leave the stat as mean; since you are pulling data for single pixels means return the value of the pixel.</p>

<pre><code class="r">flList &lt;- list(lsm=files)
varList &lt;- list(lsm=list(PRCP=&#39;precip_rate&#39;))
prcpIndex &lt;- list()
for (i in 1:length(sg$siteIds)) {
    if (!is.na(sg$ew[i]) &amp; !is.na(sg$sn[i])) {
      prcpIndex[[as.character(sg$siteIds[i])]] &lt;- list(start=c(sg$ew[i], sg$sn[i]),
                                                       end=c(sg$ew[i], sg$sn[i]), stat=&quot;mean&quot;)
   }
}
indList&lt;-list(lsm= list(PRCP = prcpIndex))
prcpData &lt;- GetMultiNcdf(file=flList,var=varList, ind=indList, parallel=FALSE)
head(prcpData)
</code></pre>

<pre><code>##                                                                                 POSIXct
## 1 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
## 2 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
## 3 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
## 4 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
## 5 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
## 6 /glade/scratch/arezoo/QPF_verification_rwrfhydro/mrms//201506160000.PRECIP_FORCING.nc
##              inds stat     statArg    variable value variableGroup
## 1 547:547,671:671 mean US10RMHS145 precip_rate     0          PRCP
## 2 703:703,667:667 mean US10buff013 precip_rate     0          PRCP
## 3 604:604,688:688 mean US10chey004 precip_rate     0          PRCP
## 4 695:695,700:700 mean US10cust042 precip_rate     0          PRCP
## 5 646:646,649:649 mean US10dund011 precip_rate     0          PRCP
## 6 712:712,705:705 mean US10garf006 precip_rate     0          PRCP
##   fileGroup
## 1       lsm
## 2       lsm
## 3       lsm
## 4       lsm
## 5       lsm
## 6       lsm
</code></pre>

<p>GetMultiNcdf pulls the time information from the netcdf files, if the data is not prepared properly, and the time info is not available it will return the name of the file instead. In the case of sample MRMS placed on the example folder, the time is not in the netcdf files, and should be retrieved from the file name which is save as column POSIXct. Also the GHCN data are converted to mm, we convert the rainrate to rain depth in an hour.</p>

<pre><code class="r">prcpData$POSIXct&lt;-strptime(regmatches(basename(prcpData$POSIXct), regexpr(&quot;[0-9].*[0-9]&quot;, basename(prcpData$POSIXct))),format = &quot;%Y%m%d%H%M&quot;, tz =&quot;UTC&quot;)
#just keep value and time to make the size small
prcpData &lt;- prcpData[,which(names(prcpData) %in% c(&#39;POSIXct&#39;,&#39;value&#39;,&#39;statArg&#39;))]
prcpData$value&lt;-prcpData$value*3600
</code></pre>

<h3>aggregating hourly data into daily.</h3>

<p>Each GHCN gauge has a unique reporting time which the daily data is been calculated based on that. The reporting time is archived in the data and is retrieved when calling GetGhcn2 function. When there is not reporting time, &ldquo;0700&rdquo; is used instead. We need to add the reporting time for each point which would be the base for daily aggregation.</p>

<pre><code class="r">sg$reportTime&lt;-obsPrcp$reportTime[match(sg$siteIds,obsPrcp$siteIds)]
        sg$reportTime[which (sg$reportTime==&quot;&quot;)]&lt;-700
</code></pre>

<p>Then you can call the CalcDailyGhcn function, you just need to change the names of the column having precipitation data into &ldquo;DEL_ACCPRCP&rdquo;.</p>

<pre><code class="r">colnames(prcpData)[3]&lt;- &quot;DEL_ACCPRCP&quot;
dailyData&lt;-CalcDailyGhcn(sg,prcpData,parallel=FALSE)
head(dailyData)
</code></pre>

<pre><code>##      ghcnDay     statArg dailyPrcp
## 1 2015-06-15 USC00020949  0.000000
## 2 2015-06-15 USC00040379  0.000000
## 3 2015-06-15 USC00247034  0.000000
## 4 2015-06-15 USC00341283  4.078394
## 5 2015-06-15 USC00423776  0.000000
## 6 2015-06-15 USC00456262  0.000000
</code></pre>

<h3>Comparing daily QPE/QPF versus GHCN-D</h3>

<p>Final step if to find the common data between the two dataset (precipitation time series (dailyData) and the observed GHCN-D (obsPrcp)).    </p>

<pre><code class="r">common&lt;-merge(dailyData,obsPrcp,
              by.x=c(&quot;ghcnDay&quot;,&quot;statArg&quot;),
              by.y=c(&quot;date&quot;,&quot;siteIds&quot;))
head(common)
</code></pre>

<pre><code>##      ghcnDay     statArg dailyPrcp element value mFlag qFlag sFlag
## 1 2015-06-15 USC00020949  0.000000    PRCP   0.0                 7
## 2 2015-06-15 USC00040379  0.000000    PRCP   0.0                 7
## 3 2015-06-15 USC00247034  0.000000    PRCP   1.3                 7
## 4 2015-06-15 USC00341283  4.078394    PRCP   3.6                 7
## 5 2015-06-15 USC00423776  0.000000    PRCP   0.0                 7
## 6 2015-06-15 USC00456262  0.000000    PRCP   0.0                 7
##   reportTime
## 1       1700
## 2       1700
## 3       1800
## 4       2400
## 5       1900
## 6       1600
</code></pre>

<p>Call the CalcMetCont function for each gauge and it returns all the statistics available.  </p>

<pre><code class="r">stat&lt;-data.frame()              
for (siteIds in unique(common$statArg)){
    df&lt;-subset(common,common$statArg==siteIds)
    stat&lt;-rbind(stat,cbind(siteIds,CalcMetCont(df$value,df$dailyPrcp)))
}
</code></pre>

<pre><code>## Error in if (stdObs &gt; 0 &amp; stdMod &gt; 0) {: missing value where TRUE/FALSE needed
</code></pre>

<pre><code class="r">str(stat)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    22 obs. of  25 variables:
##  $ siteIds    : Factor w/ 22 levels &quot;USC00020949&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ numPaired  : Factor w/ 1 level &quot;2&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ minObs     : Factor w/ 5 levels &quot;0&quot;,&quot;1.3&quot;,&quot;3.6&quot;,..: 1 1 2 3 1 1 1 1 1 1 ...
##  $ minMod     : Factor w/ 3 levels &quot;0&quot;,&quot;4.07839382387465&quot;,..: 1 1 1 2 1 1 1 1 1 1 ...
##  $ maxObs     : Factor w/ 10 levels &quot;0&quot;,&quot;10.9&quot;,&quot;3.6&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ maxMod     : Factor w/ 7 levels &quot;0&quot;,&quot;9.31633603322553&quot;,..: 1 1 2 3 1 1 1 1 4 1 ...
##  $ meanObs    : Factor w/ 10 levels &quot;0&quot;,&quot;6.1&quot;,&quot;3.6&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ meanMod    : Factor w/ 7 levels &quot;0&quot;,&quot;4.65816801661276&quot;,..: 1 1 2 3 1 1 1 1 4 1 ...
##  $ stdObs     : Factor w/ 9 levels &quot;0&quot;,&quot;6.78822509939086&quot;,..: 1 1 2 1 1 1 3 4 5 6 ...
##  $ stdMod     : Factor w/ 7 levels &quot;0&quot;,&quot;6.58764438490635&quot;,..: 1 1 2 3 1 1 1 1 4 1 ...
##  $ pearsonCor : Factor w/ 2 levels &quot;1&quot;,&quot;-1&quot;: NA NA 1 NA NA NA NA NA 2 NA ...
##  $ spearmanCor: Factor w/ 2 levels &quot;1&quot;,&quot;-1&quot;: NA NA 1 NA NA NA NA NA 2 NA ...
##  $ kendallCor : Factor w/ 2 levels &quot;1&quot;,&quot;-1&quot;: NA NA 1 NA NA NA NA NA 2 NA ...
##  $ ME         : Factor w/ 11 levels &quot;0&quot;,&quot;-1.44183198338724&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ multiBias  : Factor w/ 7 levels &quot;NaN&quot;,&quot;0.763634101084059&quot;,..: 1 1 2 3 1 1 4 4 5 4 ...
##  $ MSE        : Factor w/ 11 levels &quot;0&quot;,&quot;2.09899577982993&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ RMSE       : Factor w/ 11 levels &quot;0&quot;,&quot;1.4487911443096&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ MAE        : Factor w/ 11 levels &quot;0&quot;,&quot;1.44183198338724&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ MAD        : Factor w/ 11 levels &quot;0&quot;,&quot;1.44183198338724&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ IQR        : Factor w/ 11 levels &quot;0&quot;,&quot;0.141831983387237&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ E10        : Factor w/ 11 levels &quot;0&quot;,&quot;-1.55529757009703&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ E25        : Factor w/ 11 levels &quot;0&quot;,&quot;-1.51274797508086&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ E50        : Factor w/ 11 levels &quot;0&quot;,&quot;-1.44183198338724&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ E75        : Factor w/ 11 levels &quot;0&quot;,&quot;-1.37091599169362&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
##  $ E90        : Factor w/ 11 levels &quot;0&quot;,&quot;-1.32836639667745&quot;,..: 1 1 2 3 1 1 4 5 6 7 ...
</code></pre>

<h3>Calculate statistics over RFCs</h3>

<p>One can find out a gauge (point) falls in which RFC using GetRfc. You simply feed a dataframe at least having two columns of latitude and longitude and this functions adds a column to a dataframe with rfc name.</p>

<pre><code class="r"># add rfc name
sg &lt;- GetRfc(sg)

# check what is been added
head(sg)
</code></pre>

<pre><code>##   country network stationID latitude longitude elevation state
## 1      US       1  0RMHS145  40.5268 -105.1113    1569.1    CO
## 2      US       1  0buff013  40.6995  -99.4062     691.9    NE
## 3      US       1  0chey004  41.1548 -103.1077    1324.1    NE
## 4      US       1  0cust042  41.6273  -99.7410       0.0    NE
## 5      US       1  0dund011  40.1548 -101.4734     929.0    NE
## 6      US       1  0garf006  41.7862  -99.1309     651.1    NE
##                             name GSNflag HCN.CRNflag WMOID     siteIds  ew
## 1 RMHS 1.6 SSW                                             US10RMHS145 547
## 2 ELM CREEK 2.2 WSW                                        US10buff013 703
## 3 SIDNEY 6.8 W                                             US10chey004 604
## 4 ANSELMO 6.5 E                                            US10cust042 695
## 5 MAX 4.6 WNW                                              US10dund011 646
## 6 BURWELL 0.3 NNE                                          US10garf006 712
##    sn reportTime   rfc
## 1 671       &lt;NA&gt; MBRFC
## 2 667       &lt;NA&gt; MBRFC
## 3 688       &lt;NA&gt; MBRFC
## 4 700        700 MBRFC
## 5 649        700 MBRFC
## 6 705       &lt;NA&gt; MBRFC
</code></pre>

<p>Now you can subset the common dataframe based on RFCs, HUC6 or HUC8 and calculate statistics.</p>

<pre><code class="r">stat&lt;-data.frame()              
for (rfcs in unique(sg$rfc)){
  if (!is.na(rfcs)) {
    sitesInRfc &lt;- subset(sg,sg$rfc == rfcs)$siteIds
    df&lt;-subset(common,common$statArg %in% sitesInRfc)
    stat&lt;-rbind(stat,cbind(rfcs,CalcMetCont(df$value,df$dailyPrcp)))
  }
}
</code></pre>

<pre><code>## Error in if (stdObs &gt; 0 &amp; stdMod &gt; 0) {: missing value where TRUE/FALSE needed
</code></pre>

<p>Check the results</p>

<pre><code class="r">stat
</code></pre>

<pre><code>##       rfcs numPaired minObs minMod maxObs            maxMod
## 75%  MBRFC        63      0      0   46.2  16.2061845185235
## 75%1 SERFC        44      0      0    9.1 0.193954253336415
## 75%2 LMRFC        27      0      0   62.2  8.12915610149503
## 75%3 ABRFC        17      0      0   41.1  9.96537021928816
## 75%4 CBRFC        24      0      0      3  1.71842410345562
## 75%5 CNRFC        14      0      0      0                 0
## 75%6 MARFC        27      0      0   41.4  17.9145531146787
##                meanObs             meanMod            stdObs
## 75%   3.59365079365079    1.52131340310656  7.63831329582129
## 75%1 0.415909090909091 0.00874666798567473  1.75140384646255
## 75%2  5.24814814814815    1.19134843713861  12.4713940486086
## 75%3  4.07647058823529    1.55320840638203  10.1836590557965
## 75%4 0.170833333333333   0.242958350099798 0.626570490615497
## 75%5                 0                   0                 0
## 75%6  4.62222222222222    1.38687578412373  9.94915277928935
##                  stdMod         pearsonCor       spearmanCor
## 75%    3.34920814874746  0.522049635540498  0.46673049238258
## 75%1 0.0350875187716338 0.0645722541544994 0.447308781869688
## 75%2   2.31955332348952  0.613897343708905 0.743016773563435
## 75%3   2.75449758743542  0.773283892075676 0.742146463315782
## 75%4  0.455614712546393  0.389077865082755 0.683617031464702
## 75%5                  0               &lt;NA&gt;              &lt;NA&gt;
## 75%6   3.67725100036054 0.0702489136969021 0.548123101626806
##             kendallCor                 ME          multiBias
## 75%  0.403963245514833  -2.07233739054423  0.423333676659512
## 75%1 0.427710843373494 -0.407162422923416 0.0210302399655567
## 75%2 0.637745535138375  -4.05679971100954  0.227003583646736
## 75%3 0.631335810532222  -2.52326218185327  0.381017935187511
## 75%4 0.603381524467947 0.0721250167664645   1.42219522009638
## 75%5              &lt;NA&gt;                  0                NaN
## 75%6 0.463306214494985  -3.23534643809849  0.300045241757538
##                    MSE              RMSE               MAE
## 75%   46.4649778525677  6.81652241634748   2.6318413685844
## 75%1  3.15692996574994  1.77677515903109 0.414404053892477
## 75%2  137.211517796975  11.7137320183183  4.33500169512567
## 75%3  70.2836573835063  8.38353489785224  3.18231305549972
## 75%4 0.367482249570567 0.606203142164874  0.26379167951042
## 75%5                 0                 0                 0
## 75%6  113.858515936683  10.6704505967032  4.70959452982057
##                    MAD                IQR               E10
## 75%                0.5                1.3  -5.0587630962953
## 75%1                 0                  0                 0
## 75%2                 0   3.06301795933687 -10.8340271451068
## 75%3 0.478393823874649  0.778393823874649 -6.76011504925671
## 75%4                 0 0.0750000057450961                 0
## 75%5                 0                  0                 0
## 75%6  0.22268842906924  0.599712162429933  -13.984770645072
##                    E25 E50                E75               E90
## 75%               -1.3   0                  0 0.725030478384579
## 75%1                 0   0                  0                 0
## 75%2 -3.06301795933687   0                  0 0.691569683570415
## 75%3              -0.3   0  0.478393823874649    1.458855380686
## 75%4                 0   0 0.0750000057450961 0.575835915587959
## 75%5                 0   0                  0                 0
## 75%6 -0.51134421453462   0 0.0883679478953127  2.06208207686258
</code></pre>

<h3>Galculate statistics over HUCs</h3>

<p>HUC6 and HUC8 data are bigger than 100 MB and cannot be placed on github, therefore another function (GetPoly) is been developed to find which polygon a point falls into. One need to provide the projection for the point, address to the polygon shapefile, name of the polygon shapefile as well as the column name you want to add as a new column to your point dataframe.</p>

<pre><code class="r"># add HUC6 and HUC8 ids
sg&lt;-GetPoly(sg,  polygonAddress= &quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/gis/&quot;, polygonShapeFile= &quot;huc6&quot;, join=&quot;HUC6&quot;)
</code></pre>

<pre><code>## OGR data source with driver: ESRI Shapefile 
## Source: &quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/gis/&quot;, layer: &quot;huc6&quot;
## with 387 features and 15 fields
## Feature type: wkbPolygon with 2 dimensions
</code></pre>

<pre><code class="r">sg&lt;-GetPoly(sg,  polygonAddress= &quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/gis/&quot;, polygonShapeFile= &quot;huc8&quot;, join=&quot;HUC8&quot;)
</code></pre>

<pre><code>## OGR data source with driver: ESRI Shapefile 
## Source: &quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/gis/&quot;, layer: &quot;huc8&quot;
## with 2300 features and 15 fields
## Feature type: wkbPolygon with 2 dimensions
</code></pre>

<pre><code class="r"># check what is been added
head(sg)
</code></pre>

<pre><code>##   country network stationID elevation state                           name
## 1      US       1  0RMHS145    1569.1    CO RMHS 1.6 SSW                  
## 2      US       1  0buff013     691.9    NE ELM CREEK 2.2 WSW             
## 3      US       1  0chey004    1324.1    NE SIDNEY 6.8 W                  
## 4      US       1  0cust042       0.0    NE ANSELMO 6.5 E                 
## 5      US       1  0dund011     929.0    NE MAX 4.6 WNW                   
## 6      US       1  0garf006     651.1    NE BURWELL 0.3 NNE               
##   GSNflag HCN.CRNflag WMOID     siteIds  ew  sn reportTime   rfc   HUC6
## 1                           US10RMHS145 547 671       &lt;NA&gt; MBRFC 101900
## 2                           US10buff013 703 667       &lt;NA&gt; MBRFC 102001
## 3                           US10chey004 604 688       &lt;NA&gt; MBRFC 101900
## 4                           US10cust042 695 700        700 MBRFC 102100
## 5                           US10dund011 646 649        700 MBRFC 102500
## 6                           US10garf006 712 705       &lt;NA&gt; MBRFC 102100
##       HUC8 longitude latitude
## 1 10190007 -105.1113  40.5268
## 2 10200101  -99.4062  40.6995
## 3 10190016 -103.1077  41.1548
## 4 10210003  -99.7410  41.6273
## 5 10250004 -101.4734  40.1548
## 6 10210007  -99.1309  41.7862
</code></pre>

<p>Now you can subset the common dataframe based on HUC6 or HUC8 and calculate statistics.</p>

<h2>Gridded precipitation verification</h2>

<p>One can perform the verification of precipitation grid to gris. In order to compare the two product, they should be on the same geogrid, in other word pixels should match one by one. For example, if the QPE/QPF is going to be compared against StageIV data, then you need to use th regridding tool and regrid the StageIV into the geogrid used in your dataset. Here as an example, we use the CalcMetContGrid function to verify MRMS against StageIV. StageIV is been regridded, and regridding is not shown here.
Sample data for MRMS and StageIV is placed under &ldquo;/glade/scratch/arezoo/QPF_verification_rwrfhydro&rdquo;</p>

<p>There are two options for statistic calculation. First to read the whole data into memory and call the CalcMetContGrid to perform the analysis and return all the requested statistics in a list. However, this is not a prefered methos where dealing with big datastes or long term ones since you will face memory limitation when storing the data into memory. Therefore, there is a second option which you can provide the functions for reading of the two datasets so called obs and mod here, and define how many files to read at a time, and it will return a list of requested statistics at the end.Both options are explained below:</p>

<h3>Reading the whole dataset into memory</h3>

<p>First install rwrfhydro and load the library</p>

<pre><code class="r">rm(list=ls())
devtools::install_github(&#39;arezoorn/rwrfhydro&#39;, ref=&#39;devBranch&#39;)
library(rwrfhydro)
</code></pre>

<p>Define the path where the data reside. </p>

<pre><code class="r">dirPath&lt;-&quot;/glade/scratch/arezoo/QPF_verification_rwrfhydro/&quot;
</code></pre>

<p>Define the functions for reading the two data sets.
The following is a simple function for reading StageIV data. We subset the stageIV and MRMS to take less memory.</p>

<pre><code class="r">getPrcp&lt;-function(file,var=&quot;precip&quot;){
  nc&lt;-ncdf::open.ncdf(as.character(file))
  precip_rate&lt;- ncdf::get.var.ncdf(nc,var)
  ncdf::close.ncdf(nc)
  return(precip_rate[800:1000,800:1000])
}
</code></pre>

<p>This is a simple function for reading MRMS data used as input files in WRF-Hydro</p>

<pre><code class="r">mgetPrcp&lt;-function(file,var=&quot;precip_rate&quot;){
  nc&lt;-ncdf::open.ncdf(as.character(file))
  precip_rate&lt;- ncdf::get.var.ncdf(nc,var)
  ncdf::close.ncdf(nc)
  # we need to convert rain rate (mm/s) to rain depth (mm) to be comparable with stageIV data
  return(precip_rate[800:1000,800:1000]*3600)
}
</code></pre>

<p>Make a list of the StageIV and MRMS files. They two list should match, one by one as intended to be compared. There is not sanity check on the time stamps of the obd and mod files done in the function. Thus, we list the available MRMS files, find the time stamp for each file and build the stageIV file name corresponding to each MRMS file. </p>

<pre><code class="r">pathMRMS &lt;- paste0(dirPath,&quot;mrms/&quot;)
pathStageIV &lt;- paste0(dirPath,&quot;stageIV/&quot;)
</code></pre>

<p>list all MRMS files: </p>

<pre><code class="r">MRMS &lt;- list.files(path = pathMRMS,full.names = TRUE, pattern = glob2rx(&quot;*PRECIP_FORCING.nc&quot;))
</code></pre>

<p>Extract time stamp from the file name:</p>

<pre><code class="r">run_dates &lt;- as.POSIXct(substr(MRMS,nchar(MRMS)-29,nchar(MRMS)-20),format = &quot;%Y%m%d%H&quot;,tz = &quot;UTC&quot;)
</code></pre>

<p>Construct the name of the regridded StageIV file, corresponding to MRMS files.</p>

<pre><code class="r">stageIV &lt;- paste0(pathStageIV,format(run_dates,&quot;%Y%m%d%H&quot;),&quot;00.PRECIP_FORCING.nc&quot;)
</code></pre>

<p>And finally read all the observation (here StageIV) and model data (here MRMS) into memory. You can parallalize the reading part if you like, just note that the statistic calculation is not yet parallalized.
Also, remeber the CalcMetContGrid function only accepts an array of data which the first dimension is the time dimension, therefore, we recommend using plyr::laply for reading your data.</p>

<pre><code class="r">ncores &lt;- 16
library(doMC)
registerDoMC(ncores)

MRMSdepth &lt;- plyr::laply(as.list(MRMS),mgetPrcp,var=&quot;precip_rate&quot;, .parallel=TRUE)
stageIVdepth &lt;- plyr::laply(as.list(stageIV),getPrcp,var=&quot;precip&quot;,.parallel=TRUE)
</code></pre>

<p>Finaly, you can call the CalcMetContGrid fuction to calculate most of the common statistics for continuous variables. You need to provide the obs and mod, and the rest of options are optional. If no more information will be provided, it will calculate only the default statistics which are the following:
Number of paired data for each grid, mean of obs, mean of mod, multiplicative bias, RMSE, and pearson correlation.</p>

<pre><code class="r">stat &lt;- CalcMetContGrid(obs = stageIVdepth, mod = MRMSdepth)
str(stat)
</code></pre>

<pre><code>## List of 6
##  $ numPaired : int [1:201, 1:201] 24 24 24 24 24 24 24 24 24 24 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ meanObs   : num [1:201, 1:201] 0.0446 0.04 0.0369 0.0412 0.0405 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ meanMod   : num [1:201, 1:201] 0.025 0.0226 0.0219 0.0208 0.018 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ multiBias : num [1:201, 1:201] 1 1 1 1 1 1 1 1 1 1 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ RMSE      : num [1:201, 1:201] 0.0847 0.0782 0.0796 0.0787 0.0701 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ pearsonCor: num [1:201, 1:201] 0.762 0.756 0.708 0.714 0.752 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:201] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
</code></pre>

<p>You can be selective in statistics, just make a list of statistics. Below I have listed almost all the possible choices. If you choose quantiles, then you need to provide probs for the CalcMetContGrid function.</p>

<pre><code class="r">stat &lt;- CalcMetContGrid(stageIVdepth,MRMSdepth,
                      statList = list(&#39;numPaired&#39;,&#39;minObs&#39;,&#39;minMod&#39;,&#39;maxObs&#39;,&#39;maxMod&#39;,&#39;meanObs&#39;,&#39;meanMod&#39;,&#39;stdObs&#39;,&#39;stdMod&#39;,
                                      &#39;multiBias&#39;,&#39;ME&#39;,&#39;MSE&#39;,&#39;RMSE&#39;,&#39;MAE&#39;,&#39;pearsonCor&#39;,&#39;MAD&#39;,&#39;spearmanCor&#39;,&#39;kendallCor&#39;))
</code></pre>

<p>The examples above calculate the unconditional statistics, if interested in conditional statistics, you need to set the conRange when calling CalcMetContGrid. If conditioning is happening only on one tail, leave the second value as Inf. For example, if the statistics should be conditioned on obs &gt; 3, then define conRange as c(3,Inf) since the upper limit is infinity.</p>

<pre><code class="r">stat &lt;- CalcMetContGrid(obs = stageIVdepth, mod = MRMSdepth, conRange = c(3,Inf))
</code></pre>

<p>The CalcMetContGrid return a list of 2D maps of statistics. See what you got.</p>

<pre><code class="r">str(stat)
</code></pre>

<h3>Reading the data in pieces and calculating the statistics</h3>

<p>Due to memory limitation, sometimes it is not possible to read the whole data into memory, in that case, it is better to read the data in chunks. Then provide the name of the functions for reading the obs (here StageIV) and mod (here MRMS). The only limitation using this option is not having Median absolute error, Quantiles and Inter quantilerange of the errors can be calculated this way. kendel and spearsman options of correlation function is not available.</p>

<pre><code class="r">stat&lt;-CalcMetContGrid(obs = stageIV, mod = MRMS, .funObs = getPrcp, .funMod = mgetPrcp,
                    statList =  list(&#39;numPaired&#39;,&#39;meanObs&#39;,&#39;meanMod&#39;,&#39;stdObs&#39;,&#39;stdMod&#39;,
                                    &#39;multiBias&#39;,&#39;RMSE&#39;,&#39;MAE&#39;,&#39;pearsonCor&#39;), ncors = 10)
</code></pre>

</body>

</html>
